{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d8dfacd-89da-450d-8d63-dd16fcbf49fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1910357536.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[33], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    This notebook performs comprehensive ML diagnostics including:\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#This notebook performs comprehensive ML diagnostics including:\n",
    "#Feature importance analysis\n",
    "#SHAP (SHapley Additive exPlanations) analysis\n",
    "#Partial Dependence Plots (PDP)\n",
    "#Model performance comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e70ef6-b052-442c-96eb-0ff15886cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e1be2-889d-4131-af57-de285d989d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rom sklearn.experimental import enable_halving_search_cv  # for HalvingGridSearchCV\n",
    "from sklearn.model_selection import (\n",
    "    TimeSeriesSplit, RandomizedSearchCV, HalvingGridSearchCV\n",
    ")\n",
    "from sklearn.pipeline     import Pipeline\n",
    "from sklearn.impute       import SimpleImputer\n",
    "from sklearn.metrics      import r2_score\n",
    "from sklearn.ensemble     import RandomForestRegressor    \n",
    "from scipy.stats          import randint, loguniform\n",
    "from sklearn.ensemble     import HistGradientBoostingRegressor\n",
    "from joblib               import Memory\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed0b38-15d2-435a-9dfd-af94cc925f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "RANDOM_STATE = 0\n",
    "TIMESTAMP = \"2025-05-21 05:11:46\"\n",
    "USER = \"EricLu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b98115-04f3-4b17-bb39-9c093cd9f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Helpers & caching\n",
    "mem = Memory(\"__cache__\", verbose=0)\n",
    "\n",
    "def build_pipeline(model):\n",
    "    return Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\",   model)\n",
    "    ], memory=mem)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d52ed1-9eac-46c3-9e1f-52337d7d4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure warnings and visualization settings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# JupyterLab specific settings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f448c11-b8da-4b01-8186-f352e3acc65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set visualization style using seaborn directly instead of matplotlib style\n",
    "sns.set_style(\"whitegrid\")  # This replaces plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fdedfb95-677b-4776-92f9-719020c94569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis started by EricLu at 2025-05-21 05:11:46\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Analysis started by {USER} at {TIMESTAMP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "83623d3f-5f5e-43aa-ac90-f726aec2cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "df = pd.read_csv(\"clean_panel.csv\")\n",
    "df.sort_values([\"fyear\",\"gvkey\"], inplace=True)\n",
    "\n",
    "# Winsorize at 1st/99th pctile, log1p for positive series\n",
    "for tgt in [\"invest_cap_sum\",\"Tobins_Q\",\"DisagreementInvFCompDir\",\"debt_to_asset\"]:\n",
    "    lo, hi = df[tgt].quantile([0.01,0.99])\n",
    "    df[tgt] = df[tgt].clip(lo, hi)\n",
    "    if (df[tgt] > 0).all():\n",
    "        df[f\"log_{tgt}\"] = np.log1p(df[tgt])\n",
    "\n",
    "# Split train/test (80/20)\n",
    "train = df[df[\"fyear\"] <= 2020]\n",
    "test  = df[df[\"fyear\"] >  2020]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e27e9f30-e8a6-4581-96d2-9ddb91f0d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "features_invest = [\n",
    "    \"lag_Tobins_Q\",         # Tobin's Q at t-1\n",
    "    \"lag_invest_cap_sum\",   # invest_cap_sum at t-1\n",
    "    \"lag_cash_flow\",        # cash_flow at t-1\n",
    "    \"lag_debt_to_asset\",    # debt_to_asset at t-1\n",
    "    \"lag_equity_issuance\",  # equity_issuance at t-1\n",
    "    \"lag_ROA\",              # ROA at t-1\n",
    "    \"lag_sales_growth\",     # sales_growth at t-1\n",
    "    \"baa_rate\",         # baa_rate at t-1 (compute below)\n",
    "    \"lag_DisagreementInvFCompDir\"\n",
    "]\n",
    "\n",
    "features_disagr = [\n",
    "    \"lag_Tobins_Q\",\n",
    "    \"lag_invest_cap_sum\",\n",
    "    \"lag_cash_flow\",\n",
    "    \"lag_debt_to_asset\",\n",
    "    \"lag_equity_issuance\",\n",
    "    \"lag_ROA\",\n",
    "    \"lag_sales_growth\",\n",
    "    \"baa_rate\"\n",
    "]\n",
    "\n",
    "features_q = [\n",
    "    \"lag_invest_cap_sum\",\n",
    "    \"lag_cash_flow\",\n",
    "    \"lag_debt_to_asset\",\n",
    "    \"lag_equity_issuance\",\n",
    "    \"lag_ROA\",\n",
    "    \"lag_sales_growth\",\n",
    "    \"baa_rate\",\n",
    "    \"lag_DisagreementInvFCompDir\"\n",
    "]\n",
    "\n",
    "# And if you want a stand-alone leverage model:\n",
    "features_debt = [\n",
    "    \"lag_Tobins_Q\",\n",
    "    \"lag_invest_cap_sum\",\n",
    "    \"lag_cash_flow\",\n",
    "    \"lag_ROA\",\n",
    "    \"lag_sales_growth\",\n",
    "    \"baa_rate\",\n",
    "    \"lag_DisagreementInvFCompDir\"\n",
    "]\n",
    "\n",
    "# Make sure you actually create the `lag_baa_rate` column:\n",
    "df[\"lag_baa_rate\"] = df.groupby(\"gvkey\")[\"baa_rate\"].shift(1)\n",
    "\n",
    "# Now your target-sets dictionary (use {} not []):\n",
    "target_sets = {\n",
    "    \"invest\": (features_invest,   \"invest_cap_sum\"),\n",
    "    \"disagr\": (features_disagr,   \"DisagreementInvFCompDir\"),\n",
    "    \"q\":      (features_q,        \"Tobins_Q\"),\n",
    "    \"debt\":   (features_debt,     \"debt_to_asset\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a78f987e-c27f-45aa-831b-fec72f6fcd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "def build_pipeline(model):\n",
    "    return Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\",   model)\n",
    "    ])\n",
    "\n",
    "# Random Forest grid (kept small for notebook speed)\n",
    "rf_grid = {\n",
    "    \"model__n_estimators\":   [300, 600],\n",
    "    \"model__max_depth\":      [None, 10],\n",
    "    \"model__max_features\":   [\"sqrt\", 0.5],\n",
    "    \"model__min_samples_leaf\":[1, 5]\n",
    "}\n",
    "\n",
    "# LightGBM expanded grid\n",
    "lgb_grid = {\n",
    "    \"model__n_estimators\":      [400, 800],\n",
    "    \"model__learning_rate\":     [0.05, 0.01],\n",
    "    \"model__num_leaves\":        [31, 63, 127],\n",
    "    \"model__min_child_samples\": [5, 20],\n",
    "    \"model__min_gain_to_split\": [0.0, 0.001],\n",
    "    \"model__subsample\":         [0.8, 1.0],\n",
    "    \"model__colsample_bytree\":  [0.8, 1.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "05e1d4e8-f091-4c20-b75d-3ff2198bb239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lgb(pipe, param_grid, X, y):\n",
    "    best_estimators = []\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # Use sklearn’s GridSearch but with our own single-split CV\n",
    "        gs = GridSearchCV(\n",
    "            pipe, param_grid,\n",
    "            cv=[(train_idx, val_idx)],\n",
    "            scoring=\"r2\",\n",
    "            n_jobs=-1, refit=True, error_score=\"raise\"\n",
    "        )\n",
    "        # Early-stopping callback—works for all LightGBM versions:\n",
    "        early_cb = lgb.early_stopping(stopping_rounds=50, verbose=False)\n",
    "        gs.fit(\n",
    "            X, y,\n",
    "            **{\n",
    "                \"model__eval_set\":   [(X_val, y_val)],\n",
    "                \"model__callbacks\": [early_cb]\n",
    "            }\n",
    "        )\n",
    "        best_estimators.append((gs.best_estimator_, gs.best_score_))\n",
    "    # pick the fold with highest validation R²\n",
    "    best = max(best_estimators, key=lambda x: x[1])[0]\n",
    "    print(f\"  → LGBM best val R²: {max(e for _,e in best_estimators):.3f}\")\n",
    "    return best\n",
    "\n",
    "def tune_rf(pipe, param_grid, X, y):\n",
    "    gs = GridSearchCV(pipe, param_grid, cv=tscv,\n",
    "                      scoring=\"r2\", n_jobs=-1, refit=True,\n",
    "                      error_score=\"raise\")\n",
    "    gs.fit(X, y)\n",
    "    print(f\"  → RF best CV R²: {gs.best_score_:.3f}\")\n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d09cc8d0-fb7b-417b-98c2-e16c00e86f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Target: invest_cap_sum\n",
      "  → RF best CV R²: 0.542\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 25\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# LGBM (silent & col-wise)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m lgb_pipe \u001b[38;5;241m=\u001b[39m build_pipeline(LGBMRegressor(\n\u001b[1;32m     20\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mRANDOM_STATE,\n\u001b[1;32m     21\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     22\u001b[0m     verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     23\u001b[0m     force_col_wise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     24\u001b[0m ))\n\u001b[0;32m---> 25\u001b[0m best_lgb \u001b[38;5;241m=\u001b[39m tune_lgb(lgb_pipe, lgb_grid, X_tr, y_tr)\n\u001b[1;32m     26\u001b[0m lgb_r2   \u001b[38;5;241m=\u001b[39m r2_score(y_te, best_lgb\u001b[38;5;241m.\u001b[39mpredict(X_te))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ▶ Hold-out R²: RF = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf_r2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  |  LGBM = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlgb_r2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[128], line 16\u001b[0m, in \u001b[0;36mtune_lgb\u001b[0;34m(pipe, param_grid, X, y)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Early-stopping callback—works for all LightGBM versions:\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     early_cb \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mearly_stopping(stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m     gs\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     17\u001b[0m         X, y,\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel__eval_set\u001b[39m\u001b[38;5;124m\"\u001b[39m:   [(X_val, y_val)],\n\u001b[1;32m     20\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel__callbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: [early_cb]\n\u001b[1;32m     21\u001b[0m         }\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     best_estimators\u001b[38;5;241m.\u001b[39mappend((gs\u001b[38;5;241m.\u001b[39mbest_estimator_, gs\u001b[38;5;241m.\u001b[39mbest_score_))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# pick the fold with highest validation R²\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    966\u001b[0m         clone(base_estimator),\n\u001b[1;32m    967\u001b[0m         X,\n\u001b[1;32m    968\u001b[0m         y,\n\u001b[1;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    975\u001b[0m     )\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m )\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ## 6. Train & Evaluate in Notebook\n",
    "results = {}\n",
    "\n",
    "for name, (feat, tgt) in target_sets.items():\n",
    "    print(f\"\\n### Target: {tgt}\")\n",
    "    X_tr, y_tr = train[feat], train[tgt]\n",
    "    X_te, y_te = test[feat],  test[tgt]\n",
    "\n",
    "    # RF\n",
    "    rf_pipe = build_pipeline(RandomForestRegressor(\n",
    "        random_state=RANDOM_STATE, n_jobs=-1\n",
    "    ))\n",
    "    best_rf = tune_rf(rf_pipe, rf_grid, X_tr, y_tr)\n",
    "    rf_r2  = r2_score(y_te, best_rf.predict(X_te))\n",
    "\n",
    "    # LGBM (silent & col-wise)\n",
    "    lgb_pipe = build_pipeline(LGBMRegressor(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1,\n",
    "        force_col_wise=True\n",
    "    ))\n",
    "    best_lgb = tune_lgb(lgb_pipe, lgb_grid, X_tr, y_tr)\n",
    "    lgb_r2   = r2_score(y_te, best_lgb.predict(X_te))\n",
    "\n",
    "    print(f\"  ▶ Hold-out R²: RF = {rf_r2:.3f}  |  LGBM = {lgb_r2:.3f}\")\n",
    "    results[name] = (rf_r2, lgb_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "150ed5a1-6966-46e0-967c-c5ec11015f6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3953759278.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[44], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    if key == \"invest\":\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Diagnostics for 'invest'\n",
    "    if key == \"invest\":\n",
    "        # 1) RF Feature Importance\n",
    "        rf_model = best_rf.named_steps['model']\n",
    "        importances = rf_model.feature_importances_\n",
    "        order = np.argsort(importances)[::-1]\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.bar(range(len(feat)), importances[order])\n",
    "        plt.xticks(range(len(feat)), [feat[i] for i in order], rotation=45, ha='right')\n",
    "        plt.title('RF Feature Importance – invest_cap_sum')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb4738fa-097f-44cc-aa5d-8652a42d699a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2609668813.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[46], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    bg = X_train.sample(min(len(X_train),1000), random_state=RANDOM_STATE)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# 2) SHAP summary (LGBM)\n",
    "        bg = X_tr.sample(min(len(X_tr), 1000), random_state=RANDOM_STATE)\n",
    "        expl = shap.TreeExplainer(best_lgb.named_steps['model'], bg)\n",
    "        shap_vals = expl.shap_values(X_tr)\n",
    "        shap.summary_plot(shap_vals, X_tr, show=False)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33499327-babf-437d-80bf-566131f27c24",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2857601287.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[48], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    topN = 3\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# 3) Partial Dependence (top 3 features)\n",
    "        topN = 3\n",
    "        top_feats = [feat[i] for i in order[:topN]]\n",
    "        fig, axes = plt.subplots(1, topN, figsize=(4*topN, 3))\n",
    "        PartialDependenceDisplay.from_estimator(best_rf, X_tr, top_feats, ax=axes)\n",
    "        fig.suptitle('RF PDP – invest_cap_sum')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68f595c2-abc3-4b11-a7fc-052b0c2507a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====  Test‑set R² summary  =====\n",
      "invest   | RF = 0.493 | LGBM = 0.500\n",
      "disagr   | RF = 0.034 | LGBM = 0.021\n",
      "q        | RF = 0.115 | LGBM = 0.123\n"
     ]
    }
   ],
   "source": [
    " # 5. SUMMARY\n",
    "print(\"\\n=====  Test‑set R² summary  =====\")\n",
    "for k,v in results.items():\n",
    "    print(f\"{k:8s} | RF = {v[2]['rf_r2']:.3f} | LGBM = {v[2]['lgb_r2']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb44f3f-966a-47bf-a734-32ca12b919f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2782b0-4d10-4953-b85e-d364e7b414dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b57a6-0f13-4ae3-9aae-d36e56964d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
